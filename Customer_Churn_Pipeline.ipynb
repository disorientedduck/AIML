{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \ud83d\udee0\ufe0f End-to-End ML Pipeline with Scikit-learn\n",
        "Predict customer churn using a production-ready ML pipeline with preprocessing, training, tuning, and export."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \u2705 Step 0: Install Required Libraries\n",
        "!pip install pandas scikit-learn joblib --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \ud83d\udce5 Step 1: Load Dataset\n",
        "import pandas as pd\n",
        "url = \"https://raw.githubusercontent.com/blastchar/telco-churn/master/WA_Fn-UseC_-Telco-Customer-Churn.csv\"\n",
        "df = pd.read_csv(url)\n",
        "df = df.dropna()\n",
        "df = df[df['TotalCharges'] != ' ']\n",
        "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'])\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \ud83e\uddf9 Step 2: Define Preprocessing Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "X = df.drop(['customerID', 'Churn'], axis=1)\n",
        "y = df['Churn'].map({'Yes': 1, 'No': 0})\n",
        "\n",
        "# Identify columns\n",
        "num_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
        "cat_features = X.select_dtypes(include=['object']).columns\n",
        "\n",
        "# Preprocessing steps\n",
        "num_transformer = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "cat_transformer = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('num', num_transformer, num_features),\n",
        "    ('cat', cat_transformer, cat_features)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \ud83e\udd16 Step 3: Train Models with Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Pipeline for Logistic Regression\n",
        "logreg_pipeline = Pipeline([\n",
        "    ('preprocessing', preprocessor),\n",
        "    ('classifier', LogisticRegression(max_iter=1000))\n",
        "])\n",
        "\n",
        "# Pipeline for Random Forest\n",
        "rf_pipeline = Pipeline([\n",
        "    ('preprocessing', preprocessor),\n",
        "    ('classifier', RandomForestClassifier())\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \ud83d\udd0d Step 4: Hyperparameter Tuning with GridSearchCV\n",
        "param_grid_logreg = {\n",
        "    'classifier__C': [0.1, 1.0, 10.0]\n",
        "}\n",
        "\n",
        "param_grid_rf = {\n",
        "    'classifier__n_estimators': [50, 100],\n",
        "    'classifier__max_depth': [None, 10, 20]\n",
        "}\n",
        "\n",
        "grid_logreg = GridSearchCV(logreg_pipeline, param_grid_logreg, cv=5, scoring='accuracy')\n",
        "grid_rf = GridSearchCV(rf_pipeline, param_grid_rf, cv=5, scoring='accuracy')\n",
        "\n",
        "# Fit both models\n",
        "grid_logreg.fit(X_train, y_train)\n",
        "grid_rf.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Logistic Regression Parameters:\", grid_logreg.best_params_)\n",
        "print(\"Best Random Forest Parameters:\", grid_rf.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \ud83d\udcca Step 5: Evaluate Best Model\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "best_model = grid_rf.best_estimator_  # You can switch to grid_logreg.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"F1 Score:\", f1_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \ud83d\udcbe Step 6: Save Final Pipeline\n",
        "import joblib\n",
        "joblib.dump(best_model, \"churn_model_pipeline.joblib\")\n",
        "print(\"Pipeline saved as 'churn_model_pipeline.joblib'\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}